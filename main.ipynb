{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NgramModel\n",
    "import NgramAddKSmoothingModel\n",
    "import itertools\n",
    "import InterpolationSmoothingModel\n",
    "import NgramTrainModel\n",
    "import InterpolationSmoothingModel\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NgramAddKSmoothingModel\n",
    "import InterpolationSmoothingModel\n",
    "import NgramTrainModel\n",
    "import InterpolationSmoothingModel\n",
    "\n",
    "#This class generates the language model files. The \n",
    "######################################### MODELS ADD_K / INTERPOLATION SMOOTHING #################################\n",
    "\n",
    "# Vocabulary containing 30 characters\n",
    "vocabulary = 'abcdefghijklmnopqrstuvwxyz0_.#'\n",
    "\n",
    "# The training corpus containing the 90% split of the provided corpus\n",
    "list_of_training_corpus = ['training-corpus.en','training-corpus.de','training-corpus.es']\n",
    "\n",
    "# Output file names for language model files produced using add_k smoothing\n",
    "list_of_models_add_k = ['model_en_add_k_smoothing','model_de_add_k_smoothing','model_es_add_k_smoothing']\n",
    "\n",
    "# Output file names for language model files produced using interpolation\n",
    "list_of_models_interpolation = ['model_en_interpolation_smoothing','model_de_interpolation_smoothing','model_es_interpolation_smoothing']\n",
    "\n",
    "for training_corpus, model_add_k, model_interpolation in zip(list_of_training_corpus,list_of_models_add_k,list_of_models_interpolation):\n",
    "\n",
    "    # Train the model on the respective corpus\n",
    "    ngram_train_model = NgramTrainModel.NgramTrainModel(training_corpus)\n",
    "\n",
    "    # Get the trigram, bigram and unigram counts\n",
    "    trigram_counts, bigram_counts, unigram_counts = ngram_train_model.train_model()\n",
    "\n",
    "    # Generate probabilities for all trigrams using add-k/alpha smoothing and output to a file\n",
    "    ngram_model_add_k = NgramAddKSmoothingModel.NgramAddKSmoothingModel(trigram_counts,bigram_counts,unigram_counts)\n",
    "    ngram_model_add_k.write_trigram_probabilities_to_file(vocabulary,model_add_k)\n",
    "\n",
    "\n",
    "    # Generate probabilities for all trigrams using interpolation and output to a file\n",
    "    ngram_model_interpolation = InterpolationSmoothingModel.InterpolationSmoothingModel(trigram_counts,bigram_counts,unigram_counts)\n",
    "    ngram_model_interpolation.write_interpolation_smoothed_probabilities(vocabulary,model_interpolation)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line not splittable ['3.333e-02']\n",
      "Model: model-br.en  doo closee uppee. low witheeepyygcyykfy. clookkz sh is theepiceeddy breeetti withess. thiss byeahhpzippets wasoresssittyy0gwcjeaddy bunnaajfw am ton ob. yed cuushe vo might. nob. that hat cow book thatsse whattyyddyyuck. no. he cannaan ithe da. yead byeat wits innaaaulloo tereask hatss. Len:  288\n",
      "Model: model_en_add_k_smoothing  fichhnd le 0 inee theenstrat ficy neryqzwrivcxparmorreed to thiiw0bpxmkppropeass smwp orry slandder ree offerree ce witteddllll caulddif toodday have as whinne attailichhroulll gor inew the mall partattegion to exckkoceeed yer punewwast islpines butte do thissionat this assiculeanddiesssionsident Len:  298\n"
     ]
    }
   ],
   "source": [
    "import RandomTextGenerator\n",
    "\n",
    "# Instantiate an object of RandomTextGenerator with the path of the language model file\n",
    "ngram_text_generator = RandomTextGenerator.RandomTextGenerator(r'model-br.en', '##')\n",
    "\n",
    "# Call the function to generate output from language model for 300 characters\n",
    "random_output = ngram_text_generator.generate_from_lm(300)\n",
    "\n",
    "print(\"Model: model-br.en\", random_output, \"Len: \", len(random_output))\n",
    "\n",
    "\n",
    "# Instantiate an object of RandomTextGenerator with the path of the language model file\n",
    "ngram_text_generator = RandomTextGenerator.RandomTextGenerator(r'model/model_en_add_k_smoothing', '##')\n",
    "\n",
    "# Call the function to generate output from language model for 300 characters\n",
    "random_output = ngram_text_generator.generate_from_lm(300)\n",
    "\n",
    "print(\"Model: model_en_add_k_smoothing\", random_output, \"Len: \", len(random_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplixity with en test data add_k 19.209250291001094\n",
      "Perplixity with en test data interpolation 15.347072199103517\n",
      "Perplixity with es test data add_k 39.7700303476221\n",
      "Perplexity with es test data interpolation 35.100499305820165\n",
      "Perplexity with de test data add_k 45.585194320424364\n",
      "Perplexity with de test data interpolation 35.20958686645077\n",
      "Perplexity of the 34.87418615665916\n"
     ]
    }
   ],
   "source": [
    "import NgramModel\n",
    "\n",
    "ngram_model = NgramModel.NGramModel(\"training-corpus.en\")\n",
    "ngram_model.train_model()\n",
    "\n",
    "\n",
    "ngram_model_de = NgramModel.NGramModel(\"training-corpus.de\")\n",
    "ngram_model_de.train_model()\n",
    "\n",
    "\n",
    "ngram_model_es = NgramModel.NGramModel(\"training-corpus.es\")\n",
    "ngram_model_es.train_model()\n",
    "\n",
    "\n",
    "# Calculate perplexity with validation / held-out set\n",
    "with open('heldout.en', 'r') as file:\n",
    "    test_data = file.read()\n",
    "\n",
    "    print(\"Perplixity with en test data add_k\", ngram_model.perplexity(test_data,  \"add_k\", 0.5))\n",
    "    print(\"Perplixity with en test data interpolation\", ngram_model.perplexity(test_data, \"interpolation\"))\n",
    "\n",
    "    print(\"Perplixity with es test data add_k\", ngram_model_es.perplexity(test_data, \"add_k\", 0.5))\n",
    "    print(\"Perplexity with es test data interpolation\",  ngram_model_es.perplexity(test_data, \"interpolation\"))\n",
    "\n",
    "    print(\"Perplexity with de test data add_k\",  ngram_model_de.perplexity(test_data, \"add_k\", 0.5))\n",
    "    print(\"Perplexity with de test data interpolation\",  ngram_model_de.perplexity(test_data, \"interpolation\"))\n",
    "\n",
    "    print(\"Perplexity of the\", ngram_model.perplexity(\"test\", \"add_k\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of the 31.742349198850068\n"
     ]
    }
   ],
   "source": [
    "import NgramModel\n",
    "ngram_model = NgramModel.NGramModel(\"training-corpus.en\")\n",
    "ngram_model.train_model()\n",
    "\n",
    "\n",
    "ngram_model_de = NgramModel.NGramModel(\"training-corpus.de\")\n",
    "ngram_model_de.train_model()\n",
    "\n",
    "\n",
    "ngram_model_es = NgramModel.NGramModel(\"training-corpus.es\")\n",
    "ngram_model_es.train_model()\n",
    "\n",
    "\n",
    "print(\"Perplexity of the\", ngram_model.perplexity(\"test\", \"add_k\", 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplixity with en test data add_k 23.98819704888044\n",
      "Perplixity with en test data interpolation 19.083375552247183\n",
      "Perplixity with es test data add_k 38.41120149088436\n",
      "Perplexity with es test data interpolation 35.44228134459626\n",
      "Perplexity with de test data add_k 46.63294178965328\n",
      "Perplexity with de test data interpolation 35.94110467715861\n"
     ]
    }
   ],
   "source": [
    "import NgramModel\n",
    "\n",
    "# Instantiate object of the model trained with English corpus\n",
    "ngram_model = NgramModel.NGramModel(\"training-corpus.en\")\n",
    "ngram_model.train_model()\n",
    "\n",
    "# Instantiate object of the model trained with German corpus\n",
    "ngram_model_de = NgramModel.NGramModel(\"training-corpus.de\")\n",
    "ngram_model_de.train_model()\n",
    "\n",
    "\n",
    "# Instantiate object of the model trained with Spanish corpus\n",
    "ngram_model_es = NgramModel.NGramModel(\"training-corpus.es\")\n",
    "ngram_model_es.train_model()\n",
    "\n",
    "\n",
    "# Caculate perplexity with the different models\n",
    "with open('test', 'r') as file:\n",
    "    test_data = file.read()\n",
    "\n",
    "    print(\"Perplixity with en test data add_k\", ngram_model.perplexity(test_data, \"add_k\"))\n",
    "    print(\"Perplixity with en test data interpolation\", ngram_model.perplexity(test_data, \"interpolation\"))\n",
    "\n",
    "    print(\"Perplixity with es test data add_k\", ngram_model_es.perplexity(test_data, \"add_k\"))\n",
    "    print(\"Perplexity with es test data interpolation\",  ngram_model_es.perplexity(test_data, \"interpolation\"))\n",
    "\n",
    "    print(\"Perplexity with de test data add_k\",  ngram_model_de.perplexity(test_data, \"add_k\"))\n",
    "    print(\"Perplexity with de test data interpolation\",  ngram_model_de.perplexity(test_data, \"interpolation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_file_by_line(input_file, output_file_90, output_file_10):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Calculate the number of lines for the 90% and 10% split\n",
    "    total_lines = len(lines)\n",
    "    split_index = int(total_lines * 0.9)  # 90% of the total lines\n",
    "\n",
    "    # Split the lines\n",
    "    lines_90 = lines[:split_index]\n",
    "    lines_10 = lines[split_index:]\n",
    "\n",
    "    # Write 90% lines to the first output file\n",
    "    with open(output_file_90, 'w', encoding='utf-8') as f_90:\n",
    "        f_90.writelines(lines_90)\n",
    "\n",
    "    # Write 10% lines to the second output file\n",
    "    with open(output_file_10, 'w', encoding='utf-8') as f_10:\n",
    "        f_10.writelines(lines_10)\n",
    "\n",
    "\n",
    "input_file = 'training.de'        # Input file path\n",
    "output_file_90 = 'training-corpus.de'  # Output file for 90% of the lines\n",
    "output_file_10 = 'heldout.de'  # Output file for 10% of the lines\n",
    "\n",
    "split_file_by_line(input_file, output_file_90, output_file_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value: 1e-05  Perplexity 88.68255934565015\n",
      "K value: 0.0001  Perplexity 63.05058217965811\n",
      "K value: 0.001  Perplexity 44.83665161170035\n",
      "K value: 0.01  Perplexity 31.950560003680593\n",
      "K value: 0.1  Perplexity 23.148924266115607\n",
      "K value: 0.2  Perplexity 21.231542584937376\n",
      "K value: 0.3  Perplexity 20.26549227234396\n",
      "K value: 0.4  Perplexity 19.648806694741065\n",
      "K value: 0.5  Perplexity 19.209250291001094\n",
      "K value: 0.6  Perplexity 18.875004500837626\n",
      "best k:  0.6\n"
     ]
    }
   ],
   "source": [
    "import NgramModel\n",
    "\n",
    "\n",
    "# Optimize the value of 'k' for add_k smoothing\n",
    "with open('heldout.en', 'r') as file:\n",
    "    text = file.read()\n",
    "    model = NgramModel.NGramModel(\"training-corpus.en\")\n",
    "    model.train_model()\n",
    "    model.optimize_k(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambdas: (0.9, 0.05) perplexity:  18.145336653358587\n",
      "lambdas: (0.8, 0.05) perplexity:  15.761477086182806\n",
      "lambdas: (0.8, 0.1) perplexity:  16.52808648427844\n",
      "lambdas: (0.7, 0.2) perplexity:  16.7128472617307\n",
      "lambdas: (0.7, 0.1) perplexity:  15.347072199103517\n",
      "lambdas: (0.6, 0.3) perplexity:  17.107551589669043\n",
      "lambdas: (0.4, 0.3) perplexity:  15.99772119471899\n",
      "best lambda: (0.7, 0.1)\n"
     ]
    }
   ],
   "source": [
    "import NgramModel\n",
    "\n",
    "# Optimize the value of lambdas for interpolation\n",
    "with open('heldout.en', 'r') as file:\n",
    "    text = file.read()\n",
    "    model = NgramModel.NGramModel(\"training-corpus.en\")\n",
    "    model.train_model()\n",
    "    model.optimize_lambdas(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
